### Analysis
ReLU and GELU trained fastest. Sigmoid was the slowest due to the vanishing gradient problem in deep layers.